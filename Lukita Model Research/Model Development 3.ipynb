{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNA30iWoMLLYd4tMGwLc86a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7VXLkUuMo9x","executionInfo":{"status":"ok","timestamp":1684836762346,"user_tz":-420,"elapsed":22343,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"b668d123-7a46-4a79-c383-167fa1938766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Project "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UX7gxOrJMu_E","executionInfo":{"status":"ok","timestamp":1684836762347,"user_tz":-420,"elapsed":20,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"37666ed9-6ffa-4181-d796-bd0a6d26d111"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project\n"]}]},{"cell_type":"code","source":["module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n","handle_base, pixels, FV_SIZE = module_selection\n","MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ipBesRKMwHQ","executionInfo":{"status":"ok","timestamp":1684836762348,"user_tz":-420,"elapsed":16,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"6fde80b9-c436-4f5e-8cc0-7f514d405696"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"]}]},{"cell_type":"code","source":["! pip install Keras-Preprocessing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXRQ4AG8MyDV","executionInfo":{"status":"ok","timestamp":1684836767525,"user_tz":-420,"elapsed":5190,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"9e021fb0-ac22-4bc4-921f-2e52c1fb74f9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Keras-Preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n","Installing collected packages: Keras-Preprocessing\n","Successfully installed Keras-Preprocessing-1.1.2\n"]}]},{"cell_type":"code","source":["from keras_preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import ResNet50V2, VGG16\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, MaxPool2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Activation\n","from tensorflow.keras.models import Model\n","import pandas as pd\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","import tensorflow as tf"],"metadata":{"id":"xZTyagMTMyg1","executionInfo":{"status":"ok","timestamp":1684836772120,"user_tz":-420,"elapsed":4606,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Creating dataframe with art movement class weights\n","art_movements = pd.DataFrame()\n","art_movements['names'] = ['Academic', 'Baroque', 'Expressionism', 'Japanese', 'Neoclassicism', 'Nouveau', 'Primitivism', 'Realism', 'Renaissance', 'Rococo','Romanticism', 'Symbolism', 'Western Medieval']\n","art_movements['# of paintings'] = [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n","art_movements = art_movements.sort_values(by=['# of paintings'], ascending=False)\n","art_movements = art_movements.reset_index(drop=True)\n","art_movements['class_weight'] = art_movements['# of paintings'].sum() / (art_movements.shape[0] * art_movements['# of paintings'])\n","class_weights = art_movements['class_weight'].to_dict()\n","print(class_weights)\n","art_movements_name = art_movements['names'].values\n","print(art_movements_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkDKB4HNMzsm","executionInfo":{"status":"ok","timestamp":1684836772120,"user_tz":-420,"elapsed":9,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"02b45f3a-fc7e-412e-d1b2-98dc048ab2b0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0}\n","['Academic' 'Baroque' 'Expressionism' 'Japanese' 'Neoclassicism' 'Nouveau'\n"," 'Primitivism' 'Realism' 'Renaissance' 'Rococo' 'Romanticism' 'Symbolism'\n"," 'Western Medieval']\n"]}]},{"cell_type":"code","source":["batch_size = 64\n","train_input_shape = (256, 256, 3)\n","\n","datagen = ImageDataGenerator(\n","    rescale = 1./255.,\n","    rotation_range= 5,\n","    zoom_range=0.05,\n","    horizontal_flip=True,\n","    validation_split=0.1\n",")\n","\n","train_generator = datagen.flow_from_directory(\n","    '/content/drive/MyDrive/Project/new_dataset',\n","    target_size=train_input_shape[0:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle =True,\n","    subset='training',\n","    seed=123,\n","    classes=art_movements_name.tolist()\n",")\n","\n","validation_generator = datagen.flow_from_directory(\n","    '/content/drive/MyDrive/Project/new_dataset', #use the same data with train\n","    target_size=train_input_shape[0:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle =True,\n","    subset='validation',\n","    seed=123,\n","    classes=art_movements_name.tolist()\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfSWzOiYM0_l","executionInfo":{"status":"ok","timestamp":1684836776970,"user_tz":-420,"elapsed":4856,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"83b166df-38f2-479d-93ee-60ef6ad906d3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1200 images belonging to 13 classes.\n","Found 133 images belonging to 13 classes.\n"]}]},{"cell_type":"code","source":["# Adding model steps\n","Step_Train = train_generator.n//train_generator.batch_size\n","Step_Validation = validation_generator.n//validation_generator.batch_size\n","print(\"Total number of batches =\", Step_Train, \"and\", Step_Validation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_2MGg92M2Q-","executionInfo":{"status":"ok","timestamp":1684836776972,"user_tz":-420,"elapsed":65,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"3a6747ea-18df-4a40-eb89-8916f32e59b9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of batches = 18 and 2\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import glob \n","import os \n","import cv2\n","import math\n","from keras import applications\n","from keras.models import Sequential\n","from keras.layers import Conv2D,MaxPooling2D,Convolution2D,Activation,Flatten,Dense,Dropout,MaxPool2D,BatchNormalization\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"5qmGXsLzGacv","executionInfo":{"status":"ok","timestamp":1684836824736,"user_tz":-420,"elapsed":1197,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Convolution Neural Networks (CNN)\n","model = Sequential()\n","\n","model.add(Conv2D(8, kernel_size=(3,3), padding='same', input_shape = (256,256,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(3, 3)))\n","\n","model.add(Conv2D(16, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(13, activation='softmax'))\n","model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5w5XeYOED2h","executionInfo":{"status":"ok","timestamp":1684836826059,"user_tz":-420,"elapsed":1333,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}},"outputId":"941665f6-851d-458c-b73f-740991647f1d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 256, 256, 8)       224       \n","                                                                 \n"," activation (Activation)     (None, 256, 256, 8)       0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 85, 85, 8)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 85, 85, 16)        1168      \n","                                                                 \n"," batch_normalization (BatchN  (None, 85, 85, 16)       64        \n"," ormalization)                                                   \n","                                                                 \n"," activation_1 (Activation)   (None, 85, 85, 16)        0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 42, 42, 16)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 42, 42, 32)        4640      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 42, 42, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_2 (Activation)   (None, 42, 42, 32)        0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 21, 21, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 21, 21, 32)        9248      \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 21, 21, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_3 (Activation)   (None, 21, 21, 32)        0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 10, 10, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 3200)              0         \n","                                                                 \n"," dense (Dense)               (None, 13)                41613     \n","                                                                 \n","=================================================================\n","Total params: 57,213\n","Trainable params: 57,053\n","Non-trainable params: 160\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(train_generator, \n","          validation_data=validation_generator, \n","          epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLbb4xnpEJAS","outputId":"bdd30def-c5ec-411a-e0cb-1318d5b8c595","executionInfo":{"status":"ok","timestamp":1684841356751,"user_tz":-420,"elapsed":1217387,"user":{"displayName":"Ardelia Saphira Wedo Putri M169DSY0144","userId":"17005870322251996562"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","19/19 [==============================] - 292s 15s/step - loss: 3.1565 - accuracy: 0.0967 - val_loss: 2.5569 - val_accuracy: 0.1278\n","Epoch 2/50\n","19/19 [==============================] - 78s 4s/step - loss: 3.1029 - accuracy: 0.1017 - val_loss: 2.5705 - val_accuracy: 0.0977\n","Epoch 3/50\n","19/19 [==============================] - 83s 4s/step - loss: 3.0718 - accuracy: 0.1050 - val_loss: 2.5711 - val_accuracy: 0.0977\n","Epoch 4/50\n","19/19 [==============================] - 81s 4s/step - loss: 3.0504 - accuracy: 0.0983 - val_loss: 2.5810 - val_accuracy: 0.0752\n","Epoch 5/50\n","19/19 [==============================] - 84s 4s/step - loss: 3.0035 - accuracy: 0.1092 - val_loss: 2.5867 - val_accuracy: 0.1128\n","Epoch 6/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.9935 - accuracy: 0.1158 - val_loss: 2.5961 - val_accuracy: 0.0977\n","Epoch 7/50\n","19/19 [==============================] - 79s 4s/step - loss: 3.0008 - accuracy: 0.1058 - val_loss: 2.5986 - val_accuracy: 0.0752\n","Epoch 8/50\n","19/19 [==============================] - 82s 4s/step - loss: 2.9862 - accuracy: 0.1033 - val_loss: 2.6022 - val_accuracy: 0.0977\n","Epoch 9/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.9733 - accuracy: 0.1108 - val_loss: 2.5991 - val_accuracy: 0.0902\n","Epoch 10/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.9776 - accuracy: 0.0983 - val_loss: 2.5890 - val_accuracy: 0.0977\n","Epoch 11/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.9218 - accuracy: 0.1100 - val_loss: 2.6105 - val_accuracy: 0.0902\n","Epoch 12/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.9267 - accuracy: 0.1067 - val_loss: 2.6029 - val_accuracy: 0.0827\n","Epoch 13/50\n","19/19 [==============================] - 85s 4s/step - loss: 2.9158 - accuracy: 0.1000 - val_loss: 2.5994 - val_accuracy: 0.0677\n","Epoch 14/50\n","19/19 [==============================] - 85s 4s/step - loss: 2.8981 - accuracy: 0.1000 - val_loss: 2.6034 - val_accuracy: 0.0977\n","Epoch 15/50\n","19/19 [==============================] - 85s 4s/step - loss: 2.8606 - accuracy: 0.1133 - val_loss: 2.6327 - val_accuracy: 0.0526\n","Epoch 16/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.8685 - accuracy: 0.1058 - val_loss: 2.5882 - val_accuracy: 0.1203\n","Epoch 17/50\n","19/19 [==============================] - 89s 5s/step - loss: 2.8507 - accuracy: 0.1100 - val_loss: 2.6201 - val_accuracy: 0.1053\n","Epoch 18/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.8757 - accuracy: 0.1000 - val_loss: 2.5960 - val_accuracy: 0.1128\n","Epoch 19/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.8390 - accuracy: 0.1150 - val_loss: 2.5849 - val_accuracy: 0.1053\n","Epoch 20/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.8085 - accuracy: 0.1158 - val_loss: 2.6067 - val_accuracy: 0.1203\n","Epoch 21/50\n","19/19 [==============================] - 85s 4s/step - loss: 2.8438 - accuracy: 0.0992 - val_loss: 2.5758 - val_accuracy: 0.1429\n","Epoch 22/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.8019 - accuracy: 0.1208 - val_loss: 2.6279 - val_accuracy: 0.0827\n","Epoch 23/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.8268 - accuracy: 0.1200 - val_loss: 2.6230 - val_accuracy: 0.0977\n","Epoch 24/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.8006 - accuracy: 0.1125 - val_loss: 2.6316 - val_accuracy: 0.0977\n","Epoch 25/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.8101 - accuracy: 0.1175 - val_loss: 2.6733 - val_accuracy: 0.0752\n","Epoch 26/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.7762 - accuracy: 0.1017 - val_loss: 2.6731 - val_accuracy: 0.1128\n","Epoch 27/50\n","19/19 [==============================] - 85s 4s/step - loss: 2.7692 - accuracy: 0.1150 - val_loss: 2.6518 - val_accuracy: 0.1353\n","Epoch 28/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.7721 - accuracy: 0.1200 - val_loss: 2.7523 - val_accuracy: 0.1053\n","Epoch 29/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.7620 - accuracy: 0.1175 - val_loss: 2.6590 - val_accuracy: 0.1353\n","Epoch 30/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.7708 - accuracy: 0.1092 - val_loss: 2.6844 - val_accuracy: 0.0977\n","Epoch 31/50\n","19/19 [==============================] - 84s 4s/step - loss: 2.7519 - accuracy: 0.1117 - val_loss: 2.6926 - val_accuracy: 0.1053\n","Epoch 32/50\n","19/19 [==============================] - 79s 4s/step - loss: 2.7320 - accuracy: 0.1167 - val_loss: 2.6656 - val_accuracy: 0.1278\n","Epoch 33/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.7409 - accuracy: 0.1192 - val_loss: 2.7716 - val_accuracy: 0.1203\n","Epoch 34/50\n","19/19 [==============================] - 76s 4s/step - loss: 2.7330 - accuracy: 0.1342 - val_loss: 2.7557 - val_accuracy: 0.0752\n","Epoch 35/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7330 - accuracy: 0.1233 - val_loss: 2.7764 - val_accuracy: 0.0752\n","Epoch 36/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7505 - accuracy: 0.1267 - val_loss: 2.7597 - val_accuracy: 0.1053\n","Epoch 37/50\n","19/19 [==============================] - 77s 4s/step - loss: 2.7543 - accuracy: 0.1117 - val_loss: 2.6712 - val_accuracy: 0.0902\n","Epoch 38/50\n","19/19 [==============================] - 76s 4s/step - loss: 2.7283 - accuracy: 0.1275 - val_loss: 2.7311 - val_accuracy: 0.1278\n","Epoch 39/50\n","19/19 [==============================] - 77s 4s/step - loss: 2.6997 - accuracy: 0.1100 - val_loss: 2.6114 - val_accuracy: 0.1579\n","Epoch 40/50\n","19/19 [==============================] - 82s 4s/step - loss: 2.7327 - accuracy: 0.1183 - val_loss: 2.7644 - val_accuracy: 0.0827\n","Epoch 41/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.6896 - accuracy: 0.1192 - val_loss: 2.7560 - val_accuracy: 0.1353\n","Epoch 42/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7286 - accuracy: 0.1067 - val_loss: 2.7194 - val_accuracy: 0.1353\n","Epoch 43/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7190 - accuracy: 0.1158 - val_loss: 2.8007 - val_accuracy: 0.1203\n","Epoch 44/50\n","19/19 [==============================] - 75s 4s/step - loss: 2.7143 - accuracy: 0.1175 - val_loss: 2.7710 - val_accuracy: 0.1053\n","Epoch 45/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7088 - accuracy: 0.1225 - val_loss: 2.7441 - val_accuracy: 0.1504\n","Epoch 46/50\n","19/19 [==============================] - 81s 4s/step - loss: 2.7004 - accuracy: 0.1333 - val_loss: 2.8417 - val_accuracy: 0.1053\n","Epoch 47/50\n","19/19 [==============================] - 80s 4s/step - loss: 2.6937 - accuracy: 0.1275 - val_loss: 2.7965 - val_accuracy: 0.1128\n","Epoch 48/50\n","19/19 [==============================] - 75s 4s/step - loss: 2.6890 - accuracy: 0.1075 - val_loss: 2.6341 - val_accuracy: 0.1353\n","Epoch 49/50\n","19/19 [==============================] - 75s 4s/step - loss: 2.6830 - accuracy: 0.1258 - val_loss: 2.7917 - val_accuracy: 0.1203\n","Epoch 50/50\n","19/19 [==============================] - 75s 4s/step - loss: 2.6367 - accuracy: 0.1250 - val_loss: 2.7261 - val_accuracy: 0.1203\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe81d71ca30>"]},"metadata":{},"execution_count":12}]}]}